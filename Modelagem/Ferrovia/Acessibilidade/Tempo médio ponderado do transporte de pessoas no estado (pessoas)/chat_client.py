#!/usr/bin/env python3
"""
üîÑ Cliente Python para comunica√ß√£o com API Ollama
Vers√£o atualizada com suporte a timeout configur√°vel
"""

import requests
import json
from typing import Optional, Dict, Any

class ChatClient:
    
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url.rstrip('/')
        self.session = requests.Session()
        
        # Desabilitar proxy para localhost
        self.session.proxies = {
            'http': None,
            'https': None
        }
        
        # Configurar trust_env para False para ignorar vari√°veis de ambiente de proxy
        self.session.trust_env = False
        
    def health_check(self) -> Dict[str, Any]:
        """Verifica status da API"""
        try:
            response = self.session.get(f"{self.base_url}/health", timeout=10)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            return {"erro": str(e)}
    
    def listar_modelos(self) -> list:
        """Lista modelos dispon√≠veis"""
        try:
            response = self.session.get(f"{self.base_url}/models", timeout=15)
            response.raise_for_status()
            data = response.json()
            return data.get("modelos", [])
        except Exception as e:
            print(f"Erro ao listar modelos: {e}")
            return []
    
    def chat(self, mensagem: str, modelo: str = "tinyllama:latest", 
             stream: bool = False, timeout: int = 300, **kwargs) -> Dict[str, Any]:
        """
        Conversa com modelo - AGORA COM TIMEOUT CONFIGUR√ÅVEL
        
        Args:
            mensagem: Prompt para o modelo
            modelo: Nome do modelo a usar
            stream: Se usar streaming
            timeout: Timeout em segundos (padr√£o: 300s = 5min)
            **kwargs: Par√¢metros adicionais (temperature, top_p, etc.)
        """
        try:
            payload = {
                "modelo": modelo,
                "prompt": mensagem,
                "stream": stream,
                "timeout": timeout,  # Novo par√¢metro
                "temperature": kwargs.get("temperature", 0.7),
                "top_p": kwargs.get("top_p", 0.9),
                "top_k": kwargs.get("top_k", 40),
                "max_tokens": kwargs.get("max_tokens")
            }
            
            # Usar timeout maior no cliente para acomodar o timeout do servidor
            client_timeout = timeout + 30  # 30s extra para comunica√ß√£o
            
            response = self.session.post(
                f"{self.base_url}/chat",
                json=payload,
                timeout=client_timeout
            )
            response.raise_for_status()
            
            return response.json()
            
        except requests.exceptions.Timeout:
            return {
                "erro": f"Timeout: Modelo n√£o respondeu em {timeout}s",
                "codigo": "timeout"
            }
        except requests.exceptions.RequestException as e:
            return {
                "erro": f"Erro de conex√£o: {str(e)}",
                "codigo": "conexao"
            }
        except Exception as e:
            return {
                "erro": f"Erro inesperado: {str(e)}",
                "codigo": "interno"
            }
    
    def baixar_modelo(self, nome_modelo: str, timeout: int = 1800) -> Dict[str, Any]:
        """
        Baixa um modelo do reposit√≥rio Ollama
        
        Args:
            nome_modelo: Nome do modelo (ex: 'qwen2:0.5b')
            timeout: Timeout para download (padr√£o: 30min)
        """
        try:
            print(f"üîÑ Iniciando download do modelo: {nome_modelo}")
            print(f"‚è±Ô∏è Timeout: {timeout}s ({timeout//60} min)")
            
            payload = {"name": nome_modelo}
            
            response = self.session.post(
                f"{self.base_url}/modelo/baixar",
                json=payload,
                timeout=timeout
            )
            response.raise_for_status()
            
            result = response.json()
            print(f"‚úÖ Modelo {nome_modelo} baixado com sucesso!")
            return result
            
        except requests.exceptions.Timeout:
            return {
                "erro": f"Timeout no download ap√≥s {timeout}s",
                "codigo": "timeout_download"
            }
        except Exception as e:
            return {
                "erro": f"Erro no download: {str(e)}",
                "codigo": "download_erro"
            }
    
    def listar_modelos_detalhado(self) -> Dict[str, Any]:
        """Lista modelos com detalhes completos"""
        try:
            response = self.session.get(f"{self.base_url}/modelos", timeout=15)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            return {"erro": str(e)}
    
    def get_ollama_info(self) -> Dict[str, Any]:
        """Informa√ß√µes diretas do servidor Ollama"""
        try:
            response = self.session.get(f"{self.base_url}/ollama/version", timeout=10)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            return {"erro": str(e)}

# # Fun√ß√£o de conveni√™ncia para chat r√°pido
# def chat_rapido(pergunta: str, modelo: str = "tinyllama:latest", 
#                 timeout: int = 120) -> str:
#     """
#     Fun√ß√£o r√°pida para fazer uma pergunta
    
#     Args:
#         pergunta: Sua pergunta
#         modelo: Modelo a usar
#         timeout: Timeout em segundos (padr√£o: 2min)
    
#     Returns:
#         Resposta como string simples
#     """
#     client = ChatClient()
#     resultado = client.chat(pergunta, modelo=modelo, timeout=timeout)
    
#     if "erro" in resultado:
#         return f"ERRO: {resultado['erro']}"
    
#     return resultado.get("resposta", "Sem resposta")

# # Exemplo de uso e demonstra√ß√£o
# if __name__ == "__main__":
#     print("ü§ñ Testando Cliente Ollama com Timeout Configur√°vel")
#     print("=" * 60)
    
#     # Criar cliente
#     client = ChatClient()
    
#     # Verificar status
#     print("1. Verificando status da API...")
#     status = client.health_check()
#     print(f"   Status: {status}")
    
#     # Listar modelos
#     print("\n2. Listando modelos dispon√≠veis...")
#     modelos = client.listar_modelos()
#     print(f"   Modelos: {modelos}")
    
#     if modelos:
#         # Teste r√°pido com timeout curto
#         print("\n3. Teste r√°pido (timeout 60s)...")
#         resultado = client.chat(
#             "Responda em uma frase: o que √© IA?", 
#             modelo=modelos[0],
#             timeout=60  # 1 minuto apenas
#         )
        
#         if "erro" in resultado:
#             print(f"   ‚ùå {resultado['erro']}")
#         else:
#             print(f"   ‚úÖ Resposta: {resultado.get('resposta', 'N/A')}")
#             print(f"   ‚è±Ô∏è Tempo: {resultado.get('tempo_resposta', 'N/A')}s")
    
#     print("\n" + "=" * 60)
#     print("‚úÖ Cliente pronto para uso com timeout configur√°vel!")

