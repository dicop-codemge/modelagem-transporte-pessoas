{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ad07764",
   "metadata": {},
   "source": [
    "# üöÇ Sistema Ollama + FastAPI\n",
    "## Modelos de IA para An√°lise de Transporte Ferrovi√°rio\n",
    "\n",
    "Este notebook permite usar modelos de linguagem local para an√°lises de transporte:\n",
    "- **TinyLLama**: Modelo r√°pido e leve (1.1B par√¢metros)\n",
    "- **Qwen2:1.5b**: Modelo mais preciso (1.5B par√¢metros) - pode ser lento\n",
    "\n",
    "### ‚ö° Como usar:\n",
    "1. **IMPORTANTE**: Certifique-se de que o Docker esteja rodando: `docker compose up -d`\n",
    "2. Execute a **C√©lula 1**: Configura√ß√£o inicial\n",
    "3. Execute a **C√©lula 2**: Verificar modelos dispon√≠veis  \n",
    "4. Execute a **C√©lula 3**: Teste r√°pido\n",
    "5. Use as **C√©lulas 4-5**: Para consultas espec√≠ficas\n",
    "\n",
    "### ‚ö†Ô∏è Notas importantes:\n",
    "- Os modelos podem demorar 30-60s para responder\n",
    "- Se der timeout, tente novamente ou use o TinyLLama\n",
    "- Primeiro download dos modelos pode demorar v√°rios minutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aff14bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. CONFIGURA√á√ÉO INICIAL\n",
    "from chat_client import ChatClient\n",
    "import time\n",
    "\n",
    "# Configurar cliente\n",
    "client = ChatClient(base_url=\"http://localhost:8000\")\n",
    "\n",
    "print(\"‚úÖ Cliente configurado\")\n",
    "print(\"‚úÖ URL da API:\", client.base_url)\n",
    "\n",
    "# Verificar status da API\n",
    "try:\n",
    "    health = client.health_check()\n",
    "    print(\"‚úÖ API funcionando:\", health)\n",
    "except:\n",
    "    print(\"‚ùå API n√£o est√° respondendo. Execute: docker compose up -d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af8db9e",
   "metadata": {},
   "source": [
    "MODELOS DE BAIXO CONSUMO\n",
    "\n",
    "\"tinyllama:latest\" </br>\n",
    "\"qwen2:1.5b\"</br>\n",
    "\"deepcoder:1.5b\"</br>\n",
    "\"stablelm2:1.6b\"</br>\n",
    "\"tinydolphin:latest\"</br>\n",
    "\"exaone-deep:2.4b\"</br>\n",
    "\n",
    "</br>\n",
    "granite3.3:2b</br>\n",
    "granite3.1-dense:2b</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14db874",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos_a_baixar = [\"tinyllama:latest\",\"qwen2:1.5b\",\"qwen3:1.7b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad2dbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. VERIFICAR MODELOS DISPON√çVEIS\n",
    "print(\"Verificando modelos dispon√≠veis...\")\n",
    "\n",
    "# Listar modelos j√° instalados\n",
    "modelos_disponiveis = client.listar_modelos()\n",
    "print(f\"Modelos instalados: {modelos_disponiveis}\")\n",
    "\n",
    "# Verificar se temos os modelos necess√°rios\n",
    "for modelo in modelos_a_baixar:\n",
    "    if modelo in modelos_disponiveis:\n",
    "        print(f\"‚úì {modelo}: dispon√≠vel\")\n",
    "    else:\n",
    "        print(f\"‚úó {modelo}: n√£o encontrado, baixando\")\n",
    "        client.baixar_modelo(modelo)\n",
    "\n",
    "print(\"\\nPronto para usar os modelos dispon√≠veis!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c96672",
   "metadata": {},
   "outputs": [],
   "source": [
    "contexto = \"\"\"\n",
    "Plano Estrat√©gico Ferrovi√°rio de Minas Gerais\n",
    "Perfil da Proposta da Ferrovia para Transporte de Passageiros\n",
    "Proposta: S√£o Sebasti√£o do Rio Verde / Passa Quatro C√≥digo: TUR 59\n",
    "Categoria: Proposta Tur√≠stica Vers√£o: 00\n",
    "Tipo de empreendimento:\n",
    "Greenfield\n",
    "Brownfield (exist√™ncia da faixa de dom√≠nio,\n",
    "com reconstru√ß√£o da via permanente)\n",
    "Caracter√≠sticas f√≠sicas:\n",
    "Extens√£o (km): 25,28 Tipo bitola: -\n",
    "Total de esta√ß√µes: 3\n",
    "Esta√ß√µes atendidas (extens√£o acumulado em km):\n",
    "S√£o Sebasti√£o do Rio Verde 0,00\n",
    "Itanhandu 13,43\n",
    "Passa Quatro 25,28\n",
    "Caracter√≠sticas operacionais:\n",
    "Tempo de viagem ida (min): 76,2 Tempo de viagem ida & volta (min): 152,4\n",
    "Viagens (m√™s): 5 (ida + volta) Dias de opera√ß√£o (m√™s): 5\n",
    "Demanda (m√™s): 1.924 Produ√ß√£o quilom√©trica (km/m√™s): 252,8\n",
    "Tarifa do servi√ßo: 65,00 Tarifa ida e volta (R$)\n",
    "Desempenho da linha:\n",
    "Receita anual (R$): 1 500 720,00\n",
    "Pass.ano/km: 7,6 Receita.ano/km: 494,7\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3c228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. SUA CONSULTA PERSONALIZADA\n",
    "# Modifique a pergunta abaixo e execute para suas proprias analises\n",
    "\n",
    "# Escolha o modelo (tinyllama:latest √© mais rapido e confiavel)\n",
    "modelo = \"tinyllama:latest\"\n",
    "modelo = \"tinydolphin:latest\"  \n",
    "modelo = \"qwen2:1.5b\"  # Modelo mais confiavel\n",
    "# modelo = \"deepcoder:1.5b\"     # Erro de resposta, timeout\n",
    "# modelo = \"exaone-deep:2.4b\"   # Erro de resposta, timeout\n",
    "# modelo = \"stablelm2:1.6b\"     # Resultado 100% errado\n",
    "modelo = \"qwen3:1.7b\"         # Erro de resposta, timeout\n",
    "\n",
    "# Sua pergunta personalizada - MODIFIQUE AQUI:\n",
    "# os dados sempres estar√£o assim:  <key>: <value>\n",
    "\n",
    "print(f\"Modelo selecionado: {modelo}\")\n",
    "print(\"\\nProcessando...\")\n",
    "\n",
    "# Adicionar contexto para melhorar resposta\n",
    "prompt = f\"\"\"\n",
    "voc√™ foi designado a responder o formulario <json> com base nos dados no <contexto>,\n",
    "ent√£o responda rapidamente e com precis√£o.\n",
    "\n",
    "# Formulario JSON:\n",
    "<json>\n",
    "{{\n",
    "    \"Proposta\": value1,\n",
    "    \"C√≥digo\": value2,\n",
    "    \"Categoria\": value3,\n",
    "    \"Tipo de empreendimento\": [\"empreendimento1\", \"empreendimento2\", \"empreendimento3\" ...], # RESPONDA COM OS NOMES DOS EMPREENDIMENTOS\n",
    "\n",
    "    \"Extens√£o (km)\": value5,\n",
    "    \"Tipo bitola\": value6,\n",
    "    \"Total de esta√ß√µes\": value7,\n",
    "    \"Esta√ß√µes atendidas\": [\"esta√ß√£o1\", \"esta√ß√£o2\", \"esta√ß√£o3\" ...], # RESPONDA COM OS NOMES DE ESTA√á√ïES\n",
    "\n",
    "    \"Tempo de viagem ida (min)\": value9,\n",
    "    \"Tempo de viagem ida & volta (min)\": value10,\n",
    "    \"Viagens (m√™s)\": value11,\n",
    "    \"Dias de opera√ß√£o (m√™s)\": value12,\n",
    "    \"Demanda (m√™s)\": value13,\n",
    "    \"Produ√ß√£o quilom√©trica (km/m√™s)\": value14,\n",
    "    \"Tarifa do servi√ßo\": value15,\n",
    "\n",
    "    \"Receita anual (R$)\": value16,\n",
    "    \"Pass.ano/km\": value17,\n",
    "    \"Receita.ano/km\": value18\n",
    "}}\n",
    "</json>\n",
    "\n",
    "# Fonte de dados:\n",
    "<contexto> \n",
    "{contexto}\n",
    "</contexto> \n",
    "\n",
    "<tarefa>\n",
    "extraia os dados da fonde dados com a tag <contexto> e preencha o json com tag <json> nos campos value1, value2, etc.\n",
    "</tarefa>\n",
    "\n",
    "<resposta>\n",
    "retorne o formulario JSON preenchido, e quando falar dele inicie com a tag <json> e quando finalizar insira a tag </json>.\n",
    "</resposta>\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    inicio = time.time()\n",
    "    resposta = client.chat(prompt, modelo=modelo, stream=False, timeout=6000)\n",
    "    tempo = time.time() - inicio\n",
    "\n",
    "    print(f\"\\nTempo: {tempo:.1f}s\")\n",
    "    print(f\"\\nResposta Especializada:\")\n",
    "    print(\"=\" * 60)\n",
    "    if 'resposta' in resposta:\n",
    "        print(resposta['resposta'])\n",
    "    elif 'erro' in resposta:\n",
    "        print(f\"Erro: {resposta['erro']}\")\n",
    "    else:\n",
    "        print(str(resposta))\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(\"\\nPara fazer outra pergunta:\")\n",
    "    print(\"1. Modifique a variavel 'sua_pergunta' acima\")\n",
    "    print(\"2. Execute esta celula novamente\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro: {str(e)}\")\n",
    "    print(\"Verifique se o Docker est√° rodando: docker compose up -d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ed8fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.baixar_modelo(\"qwen3:1.7b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cfcc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd259f34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
